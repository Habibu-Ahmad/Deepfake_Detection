{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNs7TSIxHeWMhRwn0X3LFMc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Habibu-Ahmad/Deepfake_Detection/blob/main/Deeplearning_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mount Google Drive**"
      ],
      "metadata": {
        "id": "A3wOCZPS9YJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5PyytFMT9TlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imports**"
      ],
      "metadata": {
        "id": "OA3rn4IT54-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Dropout, Reshape, Concatenate, LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "agPc-LvB7thC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Loading and Processing**"
      ],
      "metadata": {
        "id": "4ZPZZ8q17vwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths to your image folders\n",
        "base_path = \"/content/drive/MyDrive/Deepfake_Images\"\n",
        "train_real_path = os.path.join(base_path, \"real_train\")\n",
        "train_fake_path = os.path.join(base_path, \"fake_train\")\n",
        "test_real_path = os.path.join(base_path, \"real_test\")\n",
        "test_fake_path = os.path.join(base_path, \"fake_test\")\n",
        "\n",
        "# Function to load images and create labels\n",
        "def load_images(folder_path, label, img_size=(224, 224)):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
        "            img_path = os.path.join(folder_path, filename)\n",
        "            try:\n",
        "                img = imread(img_path)\n",
        "                if len(img.shape) == 2:  # Convert grayscale to RGB\n",
        "                    img = np.stack((img,)*3, axis=-1)\n",
        "                img = resize(img, img_size)  # Resize to 224x224\n",
        "                images.append(img)\n",
        "                labels.append(label)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {img_path}: {e}\")\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Load training images\n",
        "print(\"Loading real training images...\")\n",
        "real_train_images, real_train_labels = load_images(train_real_path, 1)  # 1 for real\n",
        "print(\"Loading fake training images...\")\n",
        "fake_train_images, fake_train_labels = load_images(train_fake_path, 0)  # 0 for fake\n",
        "\n",
        "# Combine real and fake training images\n",
        "X_train = np.concatenate((real_train_images, fake_train_images))\n",
        "y_train = np.concatenate((real_train_labels, fake_train_labels))\n",
        "\n",
        "# Load test images\n",
        "print(\"Loading real test images...\")\n",
        "real_test_images, real_test_labels = load_images(test_real_path, 1)\n",
        "print(\"Loading fake test images...\")\n",
        "fake_test_images, fake_test_labels = load_images(test_fake_path, 0)\n",
        "\n",
        "# Combine real and fake test images\n",
        "X_test = np.concatenate((real_test_images, fake_test_images))\n",
        "y_test = np.concatenate((real_test_labels, fake_test_labels))\n",
        "\n",
        "# Shuffle training and test sets\n",
        "train_indices = np.arange(len(X_train))\n",
        "np.random.shuffle(train_indices)\n",
        "X_train = X_train[train_indices]\n",
        "y_train = y_train[train_indices]\n",
        "\n",
        "test_indices = np.arange(len(X_test))\n",
        "np.random.shuffle(test_indices)\n",
        "X_test = X_test[test_indices]\n",
        "y_test = y_test[test_indices]\n",
        "\n",
        "# Print dataset statistics\n",
        "print(f\"\\nTraining set shape: {X_train.shape}\")\n",
        "print(f\"Training labels shape: {y_train.shape}\")\n",
        "print(f\"Test set shape: {X_test.shape}\")\n",
        "print(f\"Test labels shape: {y_test.shape}\")\n",
        "print(f\"\\nClass distribution in training set - Real: {sum(y_train)}, Fake: {len(y_train)-sum(y_train)}\")\n",
        "print(f\"Class distribution in test set - Real: {sum(y_test)}, Fake: {len(y_test)-sum(y_test)}\")"
      ],
      "metadata": {
        "id": "I3PO5L7e7u3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Augmentation**"
      ],
      "metadata": {
        "id": "AhxUtDfL7_n-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data generators with augmentation for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# No augmentation for validation/test data\n",
        "test_datagen = ImageDataGenerator()\n",
        "\n",
        "# Create data generators\n",
        "batch_size = 32\n",
        "train_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size)\n",
        "test_generator = test_datagen.flow(X_test, y_test, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "0H1I1eLp8KP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Implementation**"
      ],
      "metadata": {
        "id": "YdScCtG88Rul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Meso4:\n",
        "    def __init__(self, learning_rate=0.001, img_width=224, img_height=224):\n",
        "        self.img_width = img_width\n",
        "        self.img_height = img_height\n",
        "        self.model = self.init_model()\n",
        "        optimizer = Adam(learning_rate=learning_rate)\n",
        "        self.model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    def init_model(self):\n",
        "        x = Input(shape=(self.img_width, self.img_height, 3))\n",
        "\n",
        "        # First convolutional block\n",
        "        x1 = Conv2D(8, (3, 3), padding='same', activation='relu')(x)\n",
        "        x1 = BatchNormalization()(x1)\n",
        "        x1 = MaxPooling2D(pool_size=(2, 2), padding='same')(x1)\n",
        "\n",
        "        # Second convolutional block\n",
        "        x2 = Conv2D(8, (5, 5), padding='same', activation='relu')(x1)\n",
        "        x2 = BatchNormalization()(x2)\n",
        "        x2 = MaxPooling2D(pool_size=(2, 2), padding='same')(x2)\n",
        "\n",
        "        # Third convolutional block\n",
        "        x3 = Conv2D(16, (5, 5), padding='same', activation='relu')(x2)\n",
        "        x3 = BatchNormalization()(x3)\n",
        "        x3 = MaxPooling2D(pool_size=(2, 2), padding='same')(x3)\n",
        "\n",
        "        # Fourth convolutional block\n",
        "        x4 = Conv2D(16, (5, 5), padding='same', activation='relu')(x3)\n",
        "        x4 = BatchNormalization()(x4)\n",
        "        x4 = MaxPooling2D(pool_size=(4, 4), padding='same')(x4)\n",
        "\n",
        "        # Fully connected layers\n",
        "        y = Flatten()(x4)\n",
        "        y = Dropout(0.5)(y)\n",
        "        y = Dense(16)(y)\n",
        "        y = LeakyReLU(alpha=0.1)(y)\n",
        "        y = Dropout(0.5)(y)\n",
        "        y = Dense(1, activation='sigmoid')(y)\n",
        "\n",
        "        return Model(inputs=x, outputs=y)\n",
        "\n",
        "    def fit(self, train_generator, epochs=50, validation_data=None):\n",
        "        history = self.model.fit(\n",
        "            train_generator,\n",
        "            epochs=epochs,\n",
        "            validation_data=validation_data,\n",
        "            verbose=1\n",
        "        )\n",
        "        return history\n",
        "\n",
        "    def evaluate(self, test_generator):\n",
        "        return self.model.evaluate(test_generator, verbose=1)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X)\n",
        "\n",
        "# Initialize the model\n",
        "meso_model = Meso4(learning_rate=0.001, img_width=224, img_height=224)\n",
        "meso_model.model.summary()"
      ],
      "metadata": {
        "id": "QWk6_2O58Wkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Training**"
      ],
      "metadata": {
        "id": "Doc1Fx0S8eLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define callbacks\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=5,\n",
        "    min_lr=1e-6\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "epochs = 50\n",
        "history = meso_model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=test_generator,\n",
        "    callbacks=[early_stopping, reduce_lr]\n",
        ")"
      ],
      "metadata": {
        "id": "ZuDXKVWu8jpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualization**"
      ],
      "metadata": {
        "id": "kSBvU4_W8p-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = meso_model.evaluate(test_generator)\n",
        "print(f\"\\nTest Accuracy: {test_acc:.4f}\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "# Make predictions\n",
        "y_pred_prob = meso_model.predict(X_test)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "# Calculate all metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)  # Default average='binary' for binary classification\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\n=== Comprehensive Evaluation Metrics ===\")\n",
        "print(f\"Accuracy:  {accuracy:.4f}\")  # Overall correctness\n",
        "print(f\"Precision: {precision:.4f}\") # True positives / (True positives + False positives)\n",
        "print(f\"Recall:    {recall:.4f}\")    # True positives / (True positives + False negatives)\n",
        "print(f\"F1 Score:  {f1:.4f}\")        # Harmonic mean of precision and recall\n",
        "\n",
        "# Confusion Matrix\n",
        "def plot_confusion_matrix(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Fake (0)', 'Real (1)'],\n",
        "                yticklabels=['Fake (0)', 'Real (1)'])\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.show()\n",
        "\n",
        "plot_confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# ROC Curve\n",
        "def plot_roc_curve(y_true, y_prob):\n",
        "    fpr, tpr, thresholds = roc_curve(y_true, y_prob)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "plot_roc_curve(y_test, y_pred_prob)"
      ],
      "metadata": {
        "id": "sxQICDDD8qkJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}